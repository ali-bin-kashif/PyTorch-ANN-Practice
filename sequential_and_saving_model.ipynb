{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = MNIST(root='data', train=True, download=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = 0.2\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x14578086bd0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1, 28, 28])\n",
      "torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "# Let's check the shape of the input/target data\n",
    "for data, target in train_loader:\n",
    "    print(data.shape)\n",
    "    print(target.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Flatten(),            # Flatten input from (batch_size, 28, 28) to (batch_size, 784)\n",
    "    nn.Linear(784, 512),     # First linear layer\n",
    "    nn.ReLU(),               # Activation function\n",
    "    nn.Dropout(0.3),       # Optional dropout for regularization\n",
    "    nn.Linear(512, 128),     # Second linear layer\n",
    "    nn.ReLU(),               # Activation function\n",
    "    nn.Dropout(0.3),       # Optional dropout for regularization\n",
    "    nn.Linear(128, 10)       # Output layer for 10 classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function and Optimizer\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "from torch import optim\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (2): ReLU()\n",
       "  (3): Dropout(p=0.3, inplace=False)\n",
       "  (4): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (5): ReLU()\n",
       "  (6): Dropout(p=0.3, inplace=False)\n",
       "  (7): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'cude' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cude' if torch.cuda.is_available() else 'cpu') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (2): ReLU()\n",
       "  (3): Dropout(p=0.3, inplace=False)\n",
       "  (4): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (5): ReLU()\n",
       "  (6): Dropout(p=0.3, inplace=False)\n",
       "  (7): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking the model to avialable 'device'\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.7831\n",
      "Epoch: 2, Loss: 0.3409\n",
      "Epoch: 3, Loss: 0.2662\n",
      "Epoch: 4, Loss: 0.2215\n",
      "Epoch: 5, Loss: 0.1927\n",
      "Epoch: 6, Loss: 0.1707\n",
      "Epoch: 7, Loss: 0.1522\n",
      "Epoch: 8, Loss: 0.1400\n",
      "Epoch: 9, Loss: 0.1272\n",
      "Epoch: 10, Loss: 0.1170\n",
      "CPU times: total: 6min 25s\n",
      "Wall time: 4min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(1,11):\n",
    "\n",
    "    train_loss = []\n",
    "\n",
    "    model.train()\n",
    "    for features, target in train_loader:\n",
    "        features, target = features.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(features)\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "    print(f'Epoch: {epoch}, Loss: {np.mean(train_loss):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing our model: \n",
      "\n",
      " Sequential(\n",
      "  (0): Flatten(start_dim=1, end_dim=-1)\n",
      "  (1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (2): ReLU()\n",
      "  (3): Dropout(p=0.3, inplace=False)\n",
      "  (4): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Dropout(p=0.3, inplace=False)\n",
      "  (7): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"printing our model: \\n\\n\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models layer keys: \n",
      "\n",
      " odict_keys(['1.weight', '1.bias', '4.weight', '4.bias', '7.weight', '7.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Models layer keys: \\n\\n\", model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.weight : tensor([[ 2.5667e-02, -8.6721e-03,  2.2859e-02,  ..., -2.4975e-03,\n",
      "         -6.5927e-05, -2.0415e-02],\n",
      "        [-1.7991e-02, -1.1361e-02, -1.9493e-02,  ..., -7.1986e-03,\n",
      "         -1.8471e-02,  2.0117e-02],\n",
      "        [-7.5475e-03,  5.5972e-03,  3.5059e-02,  ...,  3.5615e-02,\n",
      "         -2.1697e-02,  1.7564e-04],\n",
      "        ...,\n",
      "        [ 3.2161e-02,  7.3295e-03, -2.2093e-02,  ...,  2.6253e-02,\n",
      "          6.7193e-03,  2.5626e-02],\n",
      "        [-1.8333e-02,  3.2315e-02, -2.3867e-02,  ..., -2.1071e-02,\n",
      "          3.2737e-02,  1.7964e-02],\n",
      "        [-2.3316e-02, -1.7308e-02, -1.9036e-02,  ...,  3.5937e-02,\n",
      "          9.7518e-03, -5.6643e-03]])\n",
      "1.bias : tensor([-1.4592e-02,  1.1928e-02,  2.3046e-02, -1.6126e-02, -6.6139e-03,\n",
      "         6.8304e-03, -2.9327e-02, -1.0291e-03, -1.7379e-02, -3.1357e-02,\n",
      "         2.0865e-02,  3.2411e-04, -3.3225e-02, -1.4372e-02,  3.2821e-02,\n",
      "         1.3659e-02, -2.0996e-02,  3.1739e-02, -2.8363e-02,  4.1561e-03,\n",
      "        -3.9263e-03,  2.2866e-02,  3.2274e-02, -1.6454e-02,  1.8046e-02,\n",
      "        -1.5045e-02, -1.4483e-02,  2.9756e-03, -1.8523e-02,  2.5655e-02,\n",
      "         2.0464e-02, -7.7025e-03, -2.7145e-02,  1.3136e-03, -3.3098e-03,\n",
      "         1.1132e-02,  1.5633e-02,  5.0443e-03,  5.2264e-03, -8.2693e-03,\n",
      "        -2.4637e-02,  1.2565e-02, -2.0162e-02, -2.6446e-02,  2.7604e-02,\n",
      "         2.6983e-02,  3.6620e-02, -2.4135e-02, -3.0050e-02, -5.5939e-03,\n",
      "        -3.4752e-02, -2.8552e-02, -4.3507e-03,  5.0532e-03, -1.6820e-02,\n",
      "         7.1835e-03,  7.0735e-03, -3.4729e-02, -2.3613e-02,  2.2597e-02,\n",
      "         1.9806e-02, -3.5620e-02,  1.6945e-02,  1.2551e-02,  3.1411e-04,\n",
      "         1.7245e-03,  2.2198e-02,  3.4075e-02,  1.8556e-02, -2.9255e-02,\n",
      "         2.7696e-02, -2.1979e-03,  2.4836e-02, -3.0102e-02, -3.5051e-02,\n",
      "        -3.1344e-02, -2.9708e-02,  1.6962e-02, -3.6318e-04,  3.2670e-02,\n",
      "         1.9735e-02, -2.6748e-02, -1.8614e-02, -1.5449e-02, -2.5163e-03,\n",
      "         1.7910e-02, -3.4317e-02,  2.6698e-02,  9.2951e-04, -1.0881e-02,\n",
      "        -2.5699e-02, -3.1068e-02,  7.8589e-03, -1.8208e-02, -1.5536e-02,\n",
      "         2.5956e-02, -2.6190e-02,  3.3387e-02,  8.6476e-03, -1.4203e-03,\n",
      "        -1.6315e-02,  4.1981e-03, -2.5840e-02, -1.7817e-02,  9.6994e-03,\n",
      "        -1.0583e-02,  1.5830e-04,  9.3462e-03, -5.9956e-03, -3.0383e-02,\n",
      "        -6.9553e-03,  9.9300e-03,  1.3152e-02, -1.1914e-02,  1.4117e-02,\n",
      "         3.0512e-03, -2.0245e-02, -2.9349e-02, -1.5290e-02, -2.2758e-03,\n",
      "         1.8573e-02,  2.5795e-02,  2.5890e-02,  9.1404e-03,  1.9849e-02,\n",
      "        -1.8860e-02, -2.6540e-02,  3.2604e-02,  3.7366e-02,  2.4998e-02,\n",
      "         3.5137e-02, -2.5920e-02, -4.0894e-05,  2.8368e-02,  3.4247e-02,\n",
      "         3.7159e-02, -1.5583e-02, -1.6417e-02,  3.3707e-02,  8.8529e-03,\n",
      "         2.5955e-02,  7.6432e-03, -2.1613e-02, -1.0616e-02, -2.3746e-02,\n",
      "         2.6955e-02, -1.9593e-02,  1.1838e-02, -1.3871e-02, -1.5497e-02,\n",
      "        -3.3419e-02, -1.4470e-02,  3.0729e-02, -3.3908e-02, -3.4685e-02,\n",
      "         1.6774e-02,  5.8942e-03,  1.1032e-02,  3.8194e-03,  3.4659e-02,\n",
      "        -1.2210e-02,  1.3051e-02, -1.2181e-02, -6.8480e-03, -1.6221e-02,\n",
      "        -4.9173e-04,  2.6751e-02, -2.0647e-02,  1.6312e-02, -3.1786e-02,\n",
      "        -2.8722e-03, -1.4397e-03, -3.3173e-02, -2.7809e-02,  6.7368e-03,\n",
      "         5.5280e-03, -8.0720e-03, -1.7113e-02,  1.9133e-02,  5.1051e-03,\n",
      "         2.4001e-02, -2.5680e-02, -5.0384e-03, -3.0346e-02, -1.7237e-02,\n",
      "        -3.3026e-02,  1.5616e-02, -1.1625e-03,  1.9082e-02,  1.0211e-02,\n",
      "        -3.0747e-02,  1.1727e-02,  2.4319e-02,  3.2076e-02, -3.0776e-02,\n",
      "         2.3674e-02,  3.1773e-03,  2.6764e-02,  1.5068e-02, -2.5081e-02,\n",
      "        -2.0887e-02,  2.4253e-02, -3.4328e-02, -2.2590e-02, -2.8170e-02,\n",
      "         2.5736e-02,  2.9999e-02, -2.8626e-02, -2.5198e-02, -1.4124e-02,\n",
      "         2.4591e-02,  1.7314e-02,  1.1224e-02, -9.1777e-03, -8.5759e-03,\n",
      "        -1.2743e-02,  3.3587e-02,  1.7642e-02, -3.2164e-02, -2.5652e-02,\n",
      "         2.8540e-02, -1.0273e-02, -5.8820e-04,  8.9332e-03,  3.3193e-02,\n",
      "         1.8682e-02, -2.0267e-03, -8.8506e-03,  2.8648e-02,  1.7359e-04,\n",
      "         3.4025e-03, -3.2835e-02, -1.7367e-03,  2.2208e-02,  3.1834e-02,\n",
      "        -1.5423e-02,  1.7553e-02,  6.6827e-03, -1.8997e-02, -2.5832e-03,\n",
      "         2.7807e-02,  9.3131e-03,  1.8369e-02, -2.6850e-02,  3.5622e-02,\n",
      "         2.7999e-02, -3.2352e-02,  1.6296e-02, -4.4461e-03,  1.9887e-02,\n",
      "        -6.6416e-04, -2.2921e-02,  9.2667e-03,  1.2040e-03,  3.0080e-02,\n",
      "        -8.8907e-03,  2.5279e-02,  6.6371e-03,  3.9550e-03,  1.6855e-02,\n",
      "         8.2579e-03, -2.8590e-02,  1.6972e-02, -3.3461e-02,  9.3959e-03,\n",
      "        -3.0558e-02, -2.9532e-02,  2.3341e-02, -6.1210e-03,  2.1744e-02,\n",
      "         2.6662e-02, -1.9872e-02,  1.4604e-03, -3.2310e-02, -8.0523e-03,\n",
      "         1.9088e-02, -3.0268e-02, -1.8495e-02,  2.9456e-02, -2.1674e-02,\n",
      "        -2.5697e-02, -1.3546e-02, -1.2378e-02, -2.6617e-02,  3.2170e-02,\n",
      "        -2.2287e-02, -2.9790e-03, -1.7298e-02, -3.5465e-03, -1.2517e-02,\n",
      "         1.5863e-02,  3.5432e-02,  3.7168e-02, -1.6450e-02, -2.2063e-02,\n",
      "         6.7899e-04,  1.6022e-02,  3.5606e-03, -3.6730e-02,  1.4769e-03,\n",
      "         2.1561e-02,  2.5885e-02,  5.1620e-03, -2.7007e-02, -1.9489e-02,\n",
      "        -1.5713e-03, -1.1329e-02, -3.7190e-03,  1.5188e-03, -2.5274e-02,\n",
      "         3.0728e-02, -2.5054e-02,  2.9490e-05, -3.4704e-02, -1.8768e-02,\n",
      "         2.9604e-03,  1.2324e-02,  2.5168e-02, -2.7711e-02, -1.8122e-02,\n",
      "         5.8187e-03,  1.7615e-02, -1.2592e-02, -5.0615e-03,  1.5336e-02,\n",
      "         8.0103e-03,  2.7732e-02, -2.3255e-02, -3.9361e-02, -1.8463e-02,\n",
      "        -9.5766e-03, -2.1991e-02,  3.6803e-04,  3.0708e-02,  2.9853e-02,\n",
      "         2.6313e-02, -3.9931e-03,  2.4289e-02, -1.3496e-03,  4.5715e-03,\n",
      "        -2.3369e-02,  1.4724e-02,  2.3075e-02,  2.6026e-02,  8.7091e-03,\n",
      "         1.9117e-02, -2.4219e-02,  3.8462e-02, -2.8865e-02, -1.2679e-03,\n",
      "         3.1876e-02,  2.0563e-02, -3.5322e-02,  1.7367e-03,  2.8696e-02,\n",
      "         2.1687e-02, -1.1445e-02,  1.7896e-02, -2.5376e-02, -1.2416e-02,\n",
      "        -2.7347e-02, -3.4319e-02, -1.0809e-02, -2.2166e-02, -4.9667e-03,\n",
      "         3.4234e-02,  1.4362e-02, -2.5175e-03, -1.4443e-02,  2.7954e-02,\n",
      "        -1.1863e-02, -3.9825e-02, -3.2423e-02,  1.1167e-02, -2.0705e-03,\n",
      "        -5.6550e-03, -2.2283e-02,  1.2095e-02, -2.4786e-02, -4.9589e-03,\n",
      "         9.0707e-03,  6.4282e-03,  3.1269e-02, -1.1830e-03, -2.3184e-02,\n",
      "         9.5185e-03, -2.6431e-02, -1.2369e-03, -2.9302e-02,  2.7046e-02,\n",
      "         1.4243e-02,  6.8041e-03,  2.7075e-02, -1.2388e-02,  2.8597e-02,\n",
      "         1.2606e-02,  2.0315e-02,  2.8822e-02,  2.7943e-02,  1.8889e-03,\n",
      "        -2.7066e-02, -2.8513e-02, -1.7728e-02,  5.6021e-03,  1.3710e-02,\n",
      "        -5.9331e-03,  1.9413e-03,  1.9786e-02,  5.1748e-03, -1.7555e-02,\n",
      "        -9.0919e-03,  2.9137e-02,  1.0085e-02,  3.1995e-02, -1.6934e-02,\n",
      "        -2.3049e-02,  3.1528e-02,  8.1082e-03,  3.5977e-02, -1.5299e-02,\n",
      "        -5.7757e-03,  2.2295e-02,  2.8588e-02,  2.9949e-02, -1.2051e-02,\n",
      "        -1.3367e-03, -1.7399e-02,  2.6243e-02, -1.9630e-02, -2.7050e-02,\n",
      "        -3.1128e-02, -3.2362e-02, -1.2564e-02,  6.0738e-03, -9.6993e-03,\n",
      "         3.0677e-02, -3.5683e-02, -3.3320e-02,  1.4135e-02, -2.4215e-02,\n",
      "        -2.0292e-02, -1.3936e-04, -3.1742e-02,  3.2916e-02,  2.2236e-02,\n",
      "         3.3561e-02, -6.4161e-03,  2.3625e-02, -8.1334e-03, -5.7232e-03,\n",
      "         7.6665e-03, -2.7680e-02, -3.4426e-02,  2.0433e-02,  2.9087e-02,\n",
      "         1.3694e-02, -9.9917e-03, -2.1207e-02,  1.7063e-02, -4.4157e-03,\n",
      "         7.5734e-03,  7.7176e-03,  1.8564e-03, -3.2255e-02,  1.1826e-02,\n",
      "        -3.0003e-02,  7.4030e-03,  2.4425e-02, -4.0658e-03,  3.4857e-02,\n",
      "         3.6792e-03,  1.2815e-02, -2.0349e-02,  1.2673e-02,  2.0408e-02,\n",
      "         2.2202e-02, -5.4562e-03, -2.2953e-02, -3.5175e-02,  3.1102e-02,\n",
      "        -2.3288e-02, -1.6999e-02, -2.7429e-02,  2.4272e-03, -3.3881e-02,\n",
      "        -5.0136e-03, -3.2660e-02,  1.6666e-02,  3.7743e-04, -1.0428e-02,\n",
      "         1.6559e-02, -2.4567e-02,  1.0185e-02, -1.3980e-02,  2.8270e-02,\n",
      "        -1.1075e-02,  1.1227e-02, -1.6841e-02,  2.0496e-03, -3.8989e-02,\n",
      "         1.2409e-02,  1.8274e-02,  6.1593e-04, -1.6837e-02, -1.8178e-03,\n",
      "        -3.7118e-02, -2.5096e-02, -2.5795e-02,  1.9659e-02, -1.8404e-02,\n",
      "        -6.5454e-03,  3.1322e-02])\n",
      "4.weight : tensor([[-0.0004, -0.0512,  0.0100,  ..., -0.0297, -0.0268, -0.0153],\n",
      "        [ 0.0479, -0.0114, -0.0122,  ..., -0.0113,  0.0049, -0.0013],\n",
      "        [ 0.0310,  0.0242,  0.0219,  ..., -0.0291, -0.0332, -0.0244],\n",
      "        ...,\n",
      "        [ 0.0114, -0.0574, -0.0101,  ...,  0.0361, -0.0501,  0.0345],\n",
      "        [ 0.0775,  0.0282, -0.0261,  ..., -0.0133,  0.0446, -0.0039],\n",
      "        [ 0.0038, -0.0582,  0.0150,  ...,  0.0398, -0.0974,  0.0603]])\n",
      "4.bias : tensor([ 0.0093, -0.0180, -0.0024,  0.0460, -0.0264,  0.0360,  0.0135,  0.0099,\n",
      "         0.0178,  0.0300, -0.0235,  0.0249, -0.0341,  0.0012, -0.0233,  0.0019,\n",
      "        -0.0249,  0.0008, -0.0181, -0.0162,  0.0002,  0.0374,  0.0491,  0.0174,\n",
      "        -0.0265,  0.0015,  0.0017,  0.0328,  0.0168, -0.0159,  0.0409, -0.0343,\n",
      "        -0.0290,  0.0355, -0.0197, -0.0329,  0.0120,  0.0361,  0.0170,  0.0363,\n",
      "         0.0401, -0.0179,  0.0182, -0.0293,  0.0184, -0.0325,  0.0389, -0.0201,\n",
      "        -0.0408, -0.0290, -0.0001,  0.0078,  0.0043, -0.0159,  0.0373, -0.0405,\n",
      "        -0.0274,  0.0051,  0.0254, -0.0201,  0.0542,  0.0510, -0.0206,  0.0209,\n",
      "         0.0036, -0.0187,  0.0048,  0.0017, -0.0053,  0.0617, -0.0005, -0.0137,\n",
      "         0.0421, -0.0360,  0.0352,  0.0238,  0.0296,  0.0091,  0.0417,  0.0316,\n",
      "         0.0022,  0.0008, -0.0215, -0.0121,  0.0198,  0.0302,  0.0136,  0.0249,\n",
      "         0.0372,  0.0227, -0.0236,  0.0186,  0.0263,  0.0074,  0.0305,  0.0171,\n",
      "         0.0081,  0.0130,  0.0125, -0.0218,  0.0492, -0.0345, -0.0095,  0.0280,\n",
      "         0.0598,  0.0445,  0.0122,  0.0357, -0.0138,  0.0442,  0.0210,  0.0407,\n",
      "         0.0369, -0.0225, -0.0043, -0.0381,  0.0216,  0.0466, -0.0005,  0.0500,\n",
      "         0.0474, -0.0326,  0.0541,  0.0547,  0.0100, -0.0027,  0.0029, -0.0244])\n",
      "7.weight : tensor([[-0.1343,  0.0958,  0.1159,  ..., -0.0143, -0.1205, -0.1834],\n",
      "        [-0.1516, -0.0454, -0.0945,  ..., -0.1609, -0.1475, -0.0036],\n",
      "        [-0.0982, -0.2231,  0.0759,  ..., -0.1302,  0.1074, -0.0827],\n",
      "        ...,\n",
      "        [ 0.0739, -0.1747, -0.1654,  ...,  0.1385, -0.0852, -0.0366],\n",
      "        [-0.1156,  0.1008,  0.0494,  ...,  0.1111,  0.0733,  0.1980],\n",
      "        [-0.0744,  0.1486, -0.0017,  ..., -0.2899,  0.1170,  0.2113]])\n",
      "7.bias : tensor([-0.1181,  0.0077, -0.0732,  0.0288, -0.0126, -0.0009, -0.1360, -0.0497,\n",
      "         0.1101,  0.0662])\n"
     ]
    }
   ],
   "source": [
    "for params, values in model.state_dict().items(): \n",
    "    print(params, \":\", values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['1.weight', '1.bias', '4.weight', '4.bias', '7.weight', '7.bias'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_9932\\2208655073.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load('model.pth')\n"
     ]
    }
   ],
   "source": [
    "state_dict = torch.load('model.pth')\n",
    "print(state_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Flatten(),            # Flatten input from (batch_size, 28, 28) to (batch_size, 784)\n",
    "    nn.Linear(784, 512),     # First linear layer\n",
    "    nn.ReLU(),               # Activation function\n",
    "    nn.Dropout(0.3),       # Optional dropout for regularization\n",
    "    nn.Linear(512, 128),     # Second linear layer\n",
    "    nn.ReLU(),               # Activation function\n",
    "    nn.Dropout(0.3),       # Optional dropout for regularization\n",
    "    nn.Linear(128, 10)       # Output layer for 10 classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization:\n",
    "Added Batch Normalization after the linear but before the non linear activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=512) # batch norm layer 1\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=256) # batch norm layer 2\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.bn3 = nn.BatchNorm1d(num_features=128)  # batch norm layer 3                         \n",
    "        self.fc4 = nn.Linear(128, 56)\n",
    "        self.bn4 = nn.BatchNorm1d(num_features=56)   # batch norm layer 4 \n",
    "        self.fc5 = nn.Linear(56, 10)\n",
    "        \n",
    "        #drop out with 0.3 probability\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # input tensor is flattened \n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        # applied dropout layer\n",
    "        x = self.dropout(F.relu(self.bn1(self.fc1(x))))\n",
    "        x = self.dropout(F.relu(self.bn2(self.fc2(x))))\n",
    "        x = self.dropout(F.relu(self.bn3(self.fc3(x))))\n",
    "        x = self.dropout(F.relu(self.bn4(self.fc4(x))))\n",
    "        \n",
    "        #no dropout at the output layer\n",
    "        x = self.fc5(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function and Optimizer\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "from torch import optim\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating LR scheduler\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for epoch in range(1, 16): ## run the model for 15 epochs\n",
    "    train_loss = []\n",
    "    ## training part \n",
    "    model.train()\n",
    "    scheduler.step() # for LR scheduler\n",
    "    for data, target in train_loader:\n",
    "        \n",
    "        # Move input and label tensors to the avialable device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        #Reshaping the input data before sending into the model\n",
    "        data = data.view(data.shape[0], -1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ## 1. forward propagation\n",
    "        output = model(data)\n",
    "        \n",
    "        ## 2. loss calculation\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        ## 3. backward propagation\n",
    "        loss.backward()\n",
    "        \n",
    "        ## 4. weight optimization\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss.append(loss.item())\n",
    "        \n",
    "    print (\"Epoch:\", epoch, \"Training Loss: \", np.mean(train_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
